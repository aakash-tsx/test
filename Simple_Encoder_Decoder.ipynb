{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "MAX_LENGTH = 25\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "CLIP = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"eng_spn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = df[\"English words/sentences\"]\n",
    "target_data = df[\"French words/sentences\"].apply(lambda x: \"<sos> \" + x + \" <eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_data)\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_data)\n",
    "\n",
    "target_tokenizer = Tokenizer()\n",
    "target_tokenizer.fit_on_texts(target_data)\n",
    "target_sequences = target_tokenizer.texts_to_sequences(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "padded_input_sequences = pad_sequences(\n",
    "    input_sequences, maxlen=MAX_LENGTH, padding=\"post\"\n",
    ")\n",
    "\n",
    "padded_target_sequences = pad_sequences(\n",
    "    target_sequences, maxlen=MAX_LENGTH, padding=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab Size\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to Pytorch Tensor\n",
    "input_tensor = torch.tensor(padded_input_sequences, dtype=torch.long)\n",
    "target_tensor = torch.tensor(padded_target_sequences, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "dataloader = DataLoader(\n",
    "    TensorDataset(input_tensor, target_tensor), batch_size=BATCH_SIZE, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_dim, hidden_dim, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # Embedding layer to convert tokens into dense vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embd_dim)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            embd_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_output, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embd_dim, hidden_dim, num_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # Embedding layer to convert tokens into dense vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embd_dim)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            embd_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "\n",
    "        lstm_output = lstm_output.squeeze(1)\n",
    "\n",
    "        prediction = self.fc(lstm_output)\n",
    "\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.encoder = encoder  # Encoder for input processing\n",
    "        self.decoder = decoder  # Decoder for output generation\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        batch_size, max_length = target.size()\n",
    "        target_vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        # Tensor to store outputs for all time steps\n",
    "        outputs = torch.zeros(batch_size, max_length, target_vocab_size)\n",
    "\n",
    "        # Get initial hidden and cell states from the encoder\n",
    "        hidden, cell = self.encoder(input)\n",
    "\n",
    "        # Start decoding with the first target token\n",
    "        target_input = target[:, 0]\n",
    "\n",
    "        for t in range(1, max_length):\n",
    "            output, hidden, cell = self.decoder(target_input, hidden, cell)\n",
    "            outputs[:, t, :] = output\n",
    "            target_input = target[:, t]\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_vocab_size, EMBEDDING_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT)\n",
    "decoder = Decoder(target_vocab_size, EMBEDDING_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checkpoint\n",
    "\n",
    "\n",
    "# Saving Model\n",
    "def save_checkpoint(epoch, model, filename=\"checkpoint.pth\"):\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "        },\n",
    "        filename,\n",
    "    )\n",
    "\n",
    "\n",
    "# Loading Model\n",
    "def load_checkpoint(filename, model):\n",
    "    checkpoint = torch.load(filename)\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    start_epoch = checkpoint[\"epoch\"]\n",
    "    return start_epoch\n",
    "\n",
    "\n",
    "# Initializing Model\n",
    "try:\n",
    "    start_epoch = load_checkpoint(\"checkpoint.pth\", model)\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "except FileNotFoundError:\n",
    "    start_epoch = 1\n",
    "    print(f\"No checkpoint found, starting training from scratch...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Adam Optimizer & Loss Function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, dataloader, epochs=NUM_EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for input, target in dataloader:\n",
    "\n",
    "            # Reset Gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            output = model(input, target)\n",
    "\n",
    "            # Reshape output and target to calculate loss\n",
    "            output = output[:, 1:].reshape(-1, output.shape[2])\n",
    "            target = target[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, target)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "\n",
    "            # Clip gradients to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "\n",
    "            optimizer.step()  # Update model parameters\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        save_checkpoint(epoch, model)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {epoch_loss/len(dataloader)}\")\n",
    "        total_loss += epoch_loss\n",
    "\n",
    "    print(f\"Total Loss: {total_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "train(model, optimizer, criterion, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model, input_sequence, input_tokenizer, target_tokenizer, max_length=MAX_LENGTH\n",
    "):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Preprocess input sequence\n",
    "    input_sequence = input_tokenizer.texts_to_sequences([input_sequence])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=max_length, padding=\"post\")\n",
    "    input_tensor = torch.tensor(input_sequence, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(input_tensor)\n",
    "\n",
    "    sos_token = target_tokenizer.word_index[\"sos\"]\n",
    "    x_input = torch.tensor([sos_token], dtype=torch.long)\n",
    "\n",
    "    translated_sentence = []\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            prediction, hidden, cell = model.decoder(x_input, hidden, cell)\n",
    "\n",
    "        predicted_token = prediction.argmax(1).item()\n",
    "\n",
    "        if predicted_token == target_tokenizer.word_index[\"eos\"]:\n",
    "            break\n",
    "\n",
    "        translated_sentence.append(predicted_token)\n",
    "\n",
    "        # Update input for next step\n",
    "        x_input = torch.tensor([predicted_token], dtype=torch.long)\n",
    "\n",
    "    # Convert token IDs back to text\n",
    "    translated_sentence = target_tokenizer.sequences_to_texts([translated_sentence])[0]\n",
    "\n",
    "    return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "input_sentence = \"ill teach tom\"\n",
    "translated_sentence = predict(model, input_sentence, input_tokenizer, target_tokenizer)\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Translated Sentence: {translated_sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
